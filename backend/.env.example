# Application
APP_NAME="RAG Transcript System"
APP_VERSION="0.1.0"
ENVIRONMENT="development"  # Options: development, staging, production
DEBUG=False  # Set to True only for local debugging with detailed error messages
SECRET_KEY="your-secret-key-change-in-production"  # PRODUCTION: Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"

# API
API_V1_PREFIX="/api/v1"
BACKEND_CORS_ORIGINS=["http://localhost:3000", "http://localhost:3001", "http://localhost:8000", "http://127.0.0.1:3000", "http://127.0.0.1:3001", "http://127.0.0.1:8000"]

# Database
# PRODUCTION: Use strong password instead of "postgres" - Generate with: python -c "import secrets; print(secrets.token_urlsafe(16))"
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/rag_transcript"
DB_ECHO_SQL=False

# Redis & Celery
REDIS_URL="redis://localhost:6379/0"
CELERY_BROKER_URL="redis://localhost:6379/0"
CELERY_RESULT_BACKEND="redis://localhost:6379/0"

# Qdrant Vector Database
QDRANT_HOST="localhost"
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME="transcript_chunks"

# NextAuth.js Authentication
# PRODUCTION: Generate secret with: openssl rand -base64 32
NEXTAUTH_SECRET=""  # Must match NEXTAUTH_SECRET in frontend .env.local
ADMIN_EMAILS="admin@example.com"  # Comma-separated list of admin emails to elevate on login

# Storage (Local for development, Azure for production)
STORAGE_BACKEND="local"  # Options: "local", "azure"
LOCAL_STORAGE_PATH="./storage"

# Azure Blob Storage (for production)
AZURE_STORAGE_CONNECTION_STRING=""
AZURE_STORAGE_ACCOUNT_NAME=""
AZURE_STORAGE_ACCOUNT_KEY=""
AZURE_AUDIO_CONTAINER="audio-files"
AZURE_TRANSCRIPT_CONTAINER="transcripts"

# Whisper Transcription
WHISPER_MODEL="base"  # Options: tiny, base, small, medium, large
WHISPER_DEVICE="cpu"  # Options: cpu, cuda
WHISPER_COMPUTE_TYPE="int8"  # Options: int8, float16, float32

# Chunking Configuration
CHUNK_TARGET_TOKENS=512
CHUNK_MIN_TOKENS=256
CHUNK_MAX_TOKENS=800
CHUNK_OVERLAP_TOKENS=80
CHUNK_MAX_DURATION_SECONDS=90

# Contextual Enrichment
ENABLE_CONTEXTUAL_ENRICHMENT=True
ENRICHMENT_BATCH_SIZE=10
ENRICHMENT_MAX_RETRIES=3

# Embedding Configuration
EMBEDDING_MODEL="sentence-transformers/all-MiniLM-L6-v2"
EMBEDDING_DIMENSIONS=384
EMBEDDING_BATCH_SIZE=32
EMBEDDING_PROVIDER="local"  # Options: local, openai, azure

# LLM Provider Configuration
LLM_PROVIDER="deepseek"  # Options: deepseek (recommended), ollama, openai, anthropic, azure
LLM_MODEL="deepseek-chat"  # Default model (used when tier-specific model not available)
LLM_MAX_TOKENS=1500
LLM_TEMPERATURE=0.7

# Tier-Based Model Configuration (DeepSeek API)
# Free tier: deepseek-chat (fast, non-thinking mode)
# Paid tiers: deepseek-reasoner (advanced reasoning with chain-of-thought)
LLM_MODEL_FREE="deepseek-chat"
LLM_MODEL_PRO="deepseek-reasoner"
LLM_MODEL_ENTERPRISE="deepseek-reasoner"

# DeepSeek API (recommended for RAG - https://platform.deepseek.com)
# Pricing: $0.28/M input, $0.42/M output, $0.028/M cache hits (automatic)
DEEPSEEK_API_KEY=""  # Get from https://platform.deepseek.com/api_keys
DEEPSEEK_BASE_URL="https://api.deepseek.com/v1"
DEEPSEEK_MODEL="deepseek-chat"  # Options: deepseek-chat, deepseek-reasoner

# Ollama (Local LLM - optional fallback)
OLLAMA_BASE_URL="http://host.docker.internal:11434"
OLLAMA_MODEL="llama2"

# OpenAI
OPENAI_API_KEY=""
OPENAI_MODEL="gpt-4-turbo-preview"
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"

# Anthropic
ANTHROPIC_API_KEY=""
ANTHROPIC_MODEL="claude-3-sonnet-20240229"

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=""
AZURE_OPENAI_API_KEY=""
AZURE_OPENAI_API_VERSION="2024-02-15-preview"
AZURE_OPENAI_DEPLOYMENT_NAME=""

# RAG Configuration
RETRIEVAL_TOP_K=10
RERANKING_TOP_K=5
ENABLE_RERANKING=False

# RAG Query Expansion (improves recall by 20-30%)
ENABLE_QUERY_EXPANSION=True
QUERY_EXPANSION_VARIANTS=2

CONVERSATION_HISTORY_TOKEN_LIMIT=2000
SYSTEM_PROMPT_TOKEN_LIMIT=200
CHUNKS_TOKEN_LIMIT=2500

# Video Processing Limits
MAX_VIDEO_DURATION_SECONDS=14400  # 4 hours
MAX_VIDEO_FILE_SIZE_MB=2048  # 2 GB

# Audio Cleanup - auto-delete audio files after transcription to save storage
# When enabled, audio files are removed after successful transcription
# Set to False to keep audio files (e.g., for debugging or re-processing)
CLEANUP_AUDIO_AFTER_TRANSCRIPTION=true

# Caption Extraction - try YouTube auto-captions before falling back to Whisper
# This dramatically speeds up processing for videos with captions (1-4s vs 15-90s)
# ~95% of YouTube videos have auto-captions available
ENABLE_CAPTION_EXTRACTION=true
CAPTION_PREFERRED_LANGUAGE=en  # Preferred caption language code (en, es, fr, etc.)

# Usage Quotas (for future SaaS features)
FREE_TIER_VIDEO_LIMIT=2
FREE_TIER_MINUTES_LIMIT=60
FREE_TIER_MESSAGES_LIMIT=50
FREE_TIER_STORAGE_MB_LIMIT=1000

# Stripe Payment Integration (Get these from https://dashboard.stripe.com)
STRIPE_SECRET_KEY=""  # PRODUCTION: sk_live_... (test keys start with sk_test_...)
STRIPE_PUBLISHABLE_KEY=""  # PRODUCTION: pk_live_... (test keys start with pk_test_...)
STRIPE_WEBHOOK_SECRET=""  # Create webhook endpoint in Stripe dashboard to get this

# Stripe Price IDs (Create products and prices in Stripe dashboard)
STRIPE_PRO_MONTHLY_PRICE_ID=""  # price_xxxxxxxxxxxxxxxxxxxxx
STRIPE_PRO_YEARLY_PRICE_ID=""  # price_xxxxxxxxxxxxxxxxxxxxx
STRIPE_ENTERPRISE_MONTHLY_PRICE_ID=""  # price_xxxxxxxxxxxxxxxxxxxxx
STRIPE_ENTERPRISE_YEARLY_PRICE_ID=""  # price_xxxxxxxxxxxxxxxxxxxxx

# Logging
LOG_LEVEL="INFO"
LOG_FORMAT="json"  # Options: json, text
