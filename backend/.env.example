# Application
APP_NAME="RAG Transcript System"
APP_VERSION="0.1.0"
ENVIRONMENT="development"
DEBUG=True
SECRET_KEY="your-secret-key-change-in-production"

# API
API_V1_PREFIX="/api/v1"
BACKEND_CORS_ORIGINS=["http://localhost:3000", "http://localhost:3001", "http://localhost:8000", "http://127.0.0.1:3000", "http://127.0.0.1:3001", "http://127.0.0.1:8000"]

# Database
DATABASE_URL="postgresql://postgres:postgres@localhost:5432/rag_transcript"
DB_ECHO_SQL=False

# Redis & Celery
REDIS_URL="redis://localhost:6379/0"
CELERY_BROKER_URL="redis://localhost:6379/0"
CELERY_RESULT_BACKEND="redis://localhost:6379/0"

# Qdrant Vector Database
QDRANT_HOST="localhost"
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME="transcript_chunks"

# Clerk Authentication (Get these from https://dashboard.clerk.com)
CLERK_SECRET_KEY="sk_test_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
CLERK_PUBLISHABLE_KEY="pk_test_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
CLERK_JWT_VERIFICATION=True  # Set to False to disable JWT verification in dev (not recommended)

# Storage (Local for development, Azure for production)
STORAGE_BACKEND="local"  # Options: "local", "azure"
LOCAL_STORAGE_PATH="./storage"

# Azure Blob Storage (for production)
AZURE_STORAGE_CONNECTION_STRING=""
AZURE_STORAGE_ACCOUNT_NAME=""
AZURE_STORAGE_ACCOUNT_KEY=""
AZURE_AUDIO_CONTAINER="audio-files"
AZURE_TRANSCRIPT_CONTAINER="transcripts"

# Whisper Transcription
WHISPER_MODEL="base"  # Options: tiny, base, small, medium, large
WHISPER_DEVICE="cpu"  # Options: cpu, cuda
WHISPER_COMPUTE_TYPE="int8"  # Options: int8, float16, float32

# Chunking Configuration
CHUNK_TARGET_TOKENS=512
CHUNK_MIN_TOKENS=256
CHUNK_MAX_TOKENS=800
CHUNK_OVERLAP_TOKENS=80
CHUNK_MAX_DURATION_SECONDS=90

# Contextual Enrichment
ENABLE_CONTEXTUAL_ENRICHMENT=True
ENRICHMENT_BATCH_SIZE=10
ENRICHMENT_MAX_RETRIES=3

# Embedding Configuration
EMBEDDING_MODEL="sentence-transformers/all-MiniLM-L6-v2"
EMBEDDING_DIMENSIONS=384
EMBEDDING_BATCH_SIZE=32
EMBEDDING_PROVIDER="local"  # Options: local, openai, azure

# LLM Provider Configuration
LLM_PROVIDER="ollama"  # Options: ollama, openai, anthropic, azure
LLM_MODEL="qwen3-coder:480b-cloud"
LLM_MAX_TOKENS=1500
LLM_TEMPERATURE=0.7

# Ollama (Local LLM)
OLLAMA_BASE_URL="http://host.docker.internal:11434"
OLLAMA_MODEL="qwen3-coder:480b-cloud"

# OpenAI
OPENAI_API_KEY=""
OPENAI_MODEL="gpt-4-turbo-preview"
OPENAI_EMBEDDING_MODEL="text-embedding-3-small"

# Anthropic
ANTHROPIC_API_KEY=""
ANTHROPIC_MODEL="claude-3-sonnet-20240229"

# Azure OpenAI
AZURE_OPENAI_ENDPOINT=""
AZURE_OPENAI_API_KEY=""
AZURE_OPENAI_API_VERSION="2024-02-15-preview"
AZURE_OPENAI_DEPLOYMENT_NAME=""

# RAG Configuration
RETRIEVAL_TOP_K=10
RERANKING_TOP_K=5
ENABLE_RERANKING=False
CONVERSATION_HISTORY_TOKEN_LIMIT=2000
SYSTEM_PROMPT_TOKEN_LIMIT=200
CHUNKS_TOKEN_LIMIT=2500

# Video Processing Limits
MAX_VIDEO_DURATION_SECONDS=14400  # 4 hours
MAX_VIDEO_FILE_SIZE_MB=2048  # 2 GB
CLEANUP_AUDIO_AFTER_TRANSCRIPTION=False

# Usage Quotas (for future SaaS features)
FREE_TIER_VIDEO_LIMIT=2
FREE_TIER_MINUTES_LIMIT=60
FREE_TIER_MESSAGES_LIMIT=50
FREE_TIER_STORAGE_MB_LIMIT=1000

# Logging
LOG_LEVEL="INFO"
LOG_FORMAT="json"  # Options: json, text
